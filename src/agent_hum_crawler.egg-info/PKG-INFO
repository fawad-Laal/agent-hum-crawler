Metadata-Version: 2.4
Name: agent-hum-crawler
Version: 0.2.0
Summary: Dynamic disaster intelligence monitoring assistant
Author: Fawad
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: APScheduler>=3.10.4
Requires-Dist: beautifulsoup4>=4.12.3
Requires-Dist: feedparser>=6.0.11
Requires-Dist: httpx>=0.27.2
Requires-Dist: pdfplumber>=0.11.4
Requires-Dist: pydantic>=2.9.2
Requires-Dist: pypdf>=5.1.0
Requires-Dist: python-dotenv>=1.0.1
Requires-Dist: sqlmodel>=0.0.22
Requires-Dist: trafilatura>=1.12.2
Provides-Extra: dev
Requires-Dist: pytest>=8.3.3; extra == "dev"

ï»¿# Agent HUM Crawler

Dynamic disaster-intelligence monitoring assistant.

## Stack
- Python 3.11+
- `pydantic` for schema validation
- `httpx` for API/web requests
- `trafilatura` + `beautifulsoup4` for text extraction
- `pypdf` + `pdfplumber` for document extraction (next connectors)
- `APScheduler` for scheduling (next milestone)
- `sqlmodel` + SQLite for persisted data (next milestone)
- `pytest` for tests

## Environment
Create `.env` with:

```env
OPENAI_API_KEY=...
RELIEFWEB_APPNAME=your_approved_reliefweb_appname
```

ReliefWeb appname request: https://apidoc.reliefweb.int/parameters#appname

## Install

```powershell
python -m pip install -e .[dev]
```

## Commands

Interactive intake:

```powershell
python -m agent_hum_crawler.main intake
```

Fetch ReliefWeb with runtime filters:

```powershell
python -m agent_hum_crawler.main fetch-reliefweb --countries "Pakistan,Bangladesh" --disaster-types "flood,cyclone/storm" --interval 30 --limit 20 --include-content
```

Or use saved config:

```powershell
python -m agent_hum_crawler.main fetch-reliefweb --use-saved-config --limit 20 --include-content
```

## Tests

```powershell
pytest -q
```
